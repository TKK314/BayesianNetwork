[["index.html", "1 本サイトについて", " 1 本サイトについて Rと事例で学ぶベイジアンネットワークをもとに勉強をすすめています bnlearn - Bayesian network structure learningに参考となるdataファイルやRコードが記載されています "],["離散型データ事例.html", "2 1.離散型データ事例 2.1 1.2グラフィカル表現 2.2 1.3確率的表現 2.3 1.4パラメータの推定：条件付き確率表 2.4 1.5DAG構造の学習：検定とスコア 2.5 1.6離散型データでベイジアンネットワークを使ってみよう 2.6 1.7ベイジアンネットワークの図示", " 2 1.離散型データ事例 2.1 1.2グラフィカル表現 library(bnlearn) dag &lt;- empty.graph(nodes=c(&quot;A&quot;,&quot;S&quot;,&quot;E&quot;,&quot;O&quot;,&quot;R&quot;,&quot;T&quot;)) dag ## ## Random/Generated Bayesian network ## ## model: ## [A][S][E][O][R][T] ## nodes: 6 ## arcs: 0 ## undirected arcs: 0 ## directed arcs: 0 ## average markov blanket size: 0.00 ## average neighbourhood size: 0.00 ## average branching factor: 0.00 ## ## generation algorithm: Empty dag &lt;- set.arc(dag, from=&quot;A&quot;, to=&quot;E&quot;) dag &lt;- set.arc(dag, from=&quot;S&quot;, to=&quot;E&quot;) dag &lt;- set.arc(dag, from=&quot;E&quot;, to=&quot;O&quot;) dag &lt;- set.arc(dag, from=&quot;E&quot;, to=&quot;R&quot;) dag &lt;- set.arc(dag, from=&quot;O&quot;, to=&quot;T&quot;) dag &lt;- set.arc(dag, from=&quot;R&quot;, to=&quot;T&quot;) dag ## ## Random/Generated Bayesian network ## ## model: ## [A][S][E|A:S][O|E][R|E][T|O:R] ## nodes: 6 ## arcs: 6 ## undirected arcs: 0 ## directed arcs: 6 ## average markov blanket size: 2.67 ## average neighbourhood size: 2.00 ## average branching factor: 1.00 ## ## generation algorithm: Empty 関数の説明 nodes(dag) ## [1] &quot;A&quot; &quot;S&quot; &quot;E&quot; &quot;O&quot; &quot;R&quot; &quot;T&quot; arcs(dag) ## from to ## [1,] &quot;A&quot; &quot;E&quot; ## [2,] &quot;S&quot; &quot;E&quot; ## [3,] &quot;E&quot; &quot;O&quot; ## [4,] &quot;E&quot; &quot;R&quot; ## [5,] &quot;O&quot; &quot;T&quot; ## [6,] &quot;R&quot; &quot;T&quot; まとめてアークを追加することも可能 dag2 &lt;- empty.graph(nodes = c(&quot;A&quot;,&quot;S&quot;,&quot;E&quot;,&quot;O&quot;,&quot;R&quot;,&quot;T&quot;)) arc.set &lt;- matrix(c(&quot;A&quot;,&quot;E&quot;, &quot;S&quot;,&quot;E&quot;, &quot;E&quot;,&quot;O&quot;, &quot;E&quot;,&quot;R&quot;, &quot;O&quot;,&quot;T&quot;, &quot;R&quot;,&quot;T&quot;), byrow =TRUE, ncol = 2, dimnames = list(NULL, c(&quot;from&quot;, &quot;to&quot;))) arcs(dag2) &lt;- arc.set dag2 ## ## Random/Generated Bayesian network ## ## model: ## [A][S][E|A:S][O|E][R|E][T|O:R] ## nodes: 6 ## arcs: 6 ## undirected arcs: 0 ## directed arcs: 6 ## average markov blanket size: 2.67 ## average neighbourhood size: 2.00 ## average branching factor: 1.00 ## ## generation algorithm: Empty #同一か確認 all.equal(dag,dag2) ## [1] TRUE #循環している場合エラーがでる #set.arc(dag, from = &quot;T&quot;, to = &quot;E&quot;) 2.2 1.3確率的表現 BNを作成するに当たり変数に同時確率分布を導入する必要あり すべて離散型データなのでRにおいて水準(level)という非連続状態のデータセットを定義する必要あり A.lv &lt;-c(&quot;young&quot;,&quot;adult&quot;,&quot;old&quot;) S.lv &lt;-c(&quot;M&quot;,&quot;F&quot;) E.lv &lt;-c(&quot;high&quot;,&quot;uni&quot;) O.lv &lt;-c(&quot;emp&quot;,&quot;self&quot;) R.lv &lt;-c(&quot;small&quot;,&quot;big&quot;) T.lv &lt;-c(&quot;car&quot;,&quot;train&quot;,&quot;other&quot;) A.prob &lt;-array(c(0.30,0.50,0.20), dim=3, dimnames = list(A = A.lv)) A.prob ## A ## young adult old ## 0.3 0.5 0.2 S.prob &lt;-array(c(0.60,0.40), dim=2, dimnames = list(S = S.lv)) S.prob ## S ## M F ## 0.6 0.4 O.prob &lt;-matrix(c(0.96,0.04,0.92,0.08), ncol = 2, dimnames = list(O=O.lv, E=E.lv)) O.prob ## E ## O high uni ## emp 0.96 0.92 ## self 0.04 0.08 R.prob &lt;-matrix(c(0.25,0.75,0.20,0.80), ncol = 2, dimnames = list(R=R.lv, E=E.lv)) R.prob ## E ## R high uni ## small 0.25 0.2 ## big 0.75 0.8 E.prob &lt;-array(c(0.75,0.25,0.72,0.28,0.88,0.12,0.64,0.36,0.70,0.30,0.90,0.10), dim = c(2,3,2), dimnames = list(E=E.lv, A=A.lv, S=S.lv)) E.prob ## , , S = M ## ## A ## E young adult old ## high 0.75 0.72 0.88 ## uni 0.25 0.28 0.12 ## ## , , S = F ## ## A ## E young adult old ## high 0.64 0.7 0.9 ## uni 0.36 0.3 0.1 T.prob &lt;-array(c(0.48,0.42,0.10,0.56,0.36,0.08,0.58,0.24,0.18,0.70,0.21,0.09), dim = c(3,2,2), dimnames = list(T=T.lv, O=O.lv, R=R.lv)) T.prob ## , , R = small ## ## O ## T emp self ## car 0.48 0.56 ## train 0.42 0.36 ## other 0.10 0.08 ## ## , , R = big ## ## O ## T emp self ## car 0.58 0.70 ## train 0.24 0.21 ## other 0.18 0.09 上記の条件付き確率表とDAGを組み合わせる必要あり #以下のように直接ネットワークを記述することも可能 dag3 &lt;- model2network(&quot;[A][S][E|A:S][O|E][R|E][T|O:R]&quot;) #cptは条件付き確率表を意味する cpt &lt;- list(A = A.prob, S = S.prob, E = E.prob, O = O.prob, R = R.prob, T= T.prob) bn &lt;- custom.fit(dag, cpt) #パラメータ数確認 nparams(bn) ## [1] 21 #arc確認 arcs(bn) ## from to ## [1,] &quot;A&quot; &quot;E&quot; ## [2,] &quot;S&quot; &quot;E&quot; ## [3,] &quot;E&quot; &quot;O&quot; ## [4,] &quot;E&quot; &quot;R&quot; ## [5,] &quot;O&quot; &quot;T&quot; ## [6,] &quot;R&quot; &quot;T&quot; #条件付き確率表を示せる bn$R ## ## Parameters of node R (multinomial distribution) ## ## Conditional probability table: ## ## E ## R high uni ## small 0.25 0.20 ## big 0.75 0.80 #条件付き確率表部分のみを出せる coef(bn$R) ## E ## R high uni ## small 0.25 0.20 ## big 0.75 0.80 #全体を示す bn ## ## Bayesian network parameters ## ## Parameters of node A (multinomial distribution) ## ## Conditional probability table: ## A ## young adult old ## 0.3 0.5 0.2 ## ## Parameters of node S (multinomial distribution) ## ## Conditional probability table: ## S ## M F ## 0.6 0.4 ## ## Parameters of node E (multinomial distribution) ## ## Conditional probability table: ## ## , , S = M ## ## A ## E young adult old ## high 0.75 0.72 0.88 ## uni 0.25 0.28 0.12 ## ## , , S = F ## ## A ## E young adult old ## high 0.64 0.70 0.90 ## uni 0.36 0.30 0.10 ## ## ## Parameters of node O (multinomial distribution) ## ## Conditional probability table: ## ## E ## O high uni ## emp 0.96 0.92 ## self 0.04 0.08 ## ## Parameters of node R (multinomial distribution) ## ## Conditional probability table: ## ## E ## R high uni ## small 0.25 0.20 ## big 0.75 0.80 ## ## Parameters of node T (multinomial distribution) ## ## Conditional probability table: ## ## , , R = small ## ## O ## T emp self ## car 0.48 0.56 ## train 0.42 0.36 ## other 0.10 0.08 ## ## , , R = big ## ## O ## T emp self ## car 0.58 0.70 ## train 0.24 0.21 ## other 0.18 0.09 2.3 1.4パラメータの推定：条件付き確率表 survey &lt;- read.table(&quot;data/survey.txt&quot;, header = TRUE, colClasses = &quot;factor&quot;) パラメータ=局所的分布における条件付き確率そのもの #bn.fit関数を用いることでデータからパラメータ推定可能 #mleは最尤推定法を用いている bn.mle &lt;- bn.fit(dag, data = survey, method = &quot;mle&quot;) bn.mle$O ## ## Parameters of node O (multinomial distribution) ## ## Conditional probability table: ## ## E ## O high uni ## emp 0.98082192 0.92592593 ## self 0.01917808 0.07407407 #bayesにすると事後分布を用いたベイズ的方法になる bn.bayes &lt;- bn.fit(dag, data = survey, method = &quot;bayes&quot;, iss = 10) bn.bayes$O ## ## Parameters of node O (multinomial distribution) ## ## Conditional probability table: ## ## E ## O high uni ## emp 0.97432432 0.91071429 ## self 0.02567568 0.08928571 iss (imaginary sample size)はオプション：事前分布にどの程度重み付けするか 小さい値（1-15）にするのが一般的、値が大きいと事後分布が一様になり事前分布として用いられた一様分布へと近似していく ベイズのほうがより1から遠い値となる→0を含むセルが減る 最尤推定法よりもロバストで予測力の高いベイジアンネットワークを構築可能 2.4 1.5DAG構造の学習：検定とスコア DAGの構造を探索していくこと自体が調査の目的の場合もある どのノードが分析対象のノードと直接関連があるか特定可能 2.4.1 1.5.1条件付き独立性検定 個々のアークの有無に焦点を当てたもの 条件付き独立の帰無仮説（確率的に独立である）が棄却されるならそのアークをDAGの中に加えることができる #ci.test関数で対数尤度比検定、Χ2検定が可能 ci.test(&quot;T&quot;,&quot;E&quot;,c(&quot;O&quot;,&quot;R&quot;),test = &quot;mi&quot;, data = survey) ## ## Mutual Information (disc.) ## ## data: T ~ E | O + R ## mi = 9.8836, df = 8, p-value = 0.2733 ## alternative hypothesis: true value is greater than 0 ci.test(&quot;T&quot;,&quot;E&quot;,c(&quot;O&quot;,&quot;R&quot;),test = &quot;x2&quot;, data = survey) ## ## Pearson&#39;s X^2 ## ## data: T ~ E | O + R ## x2 = 8.2375, df = 8, p-value = 0.4106 ## alternative hypothesis: true value is greater than 0 いずれもp値が大きいため、E→Tの関連性で有意差なし→現在のDAG構造に加えるような関連性なし #まとめて検定を実施可能 arc.strength(dag, data = survey, criterion = &quot;x2&quot;) ## from to strength ## 1 A E 0.0009777168 ## 2 S E 0.0012537013 ## 3 E O 0.0026379469 ## 4 E R 0.0005599201 ## 5 O T 0.4339127237 ## 6 R T 0.0013584250 O→T以外のすべてのアークは支持されたものと判断可能 2.4.2 1.5.2ネットワークスコア ネットワーク全体としてのDAGに焦点を当てている。 DAGがデータの依存構造をどの程度よく反映しているかの適合度指標 \\[ BIC = \\log\\widehat{Pr}(A,S,E,O,R,T) - \\frac{d}{2}\\log n \\] n：サンプルサイズ、d：ネットワーク全体のパラメータ数 DAGがデータにフィットしているほど高い値を示す #BIC score(dag, data = survey, type = &quot;bic&quot;) ## [1] -2012.687 #対数BDe score(dag, data = survey, type = &quot;bde&quot;, iss = 10) ## [1] -1998.284 #例としてランダムグラフを作ってみるとさすがにスコアが悪い rnd &lt;- random.graph(nodes = c(&quot;A&quot;,&quot;S&quot;,&quot;E&quot;,&quot;O&quot;,&quot;R&quot;,&quot;T&quot;)) modelstring(rnd) ## [1] &quot;[A][S|A][E|A][O|S][R|S:O][T|A:R]&quot; score(rnd, data = survey, type = &quot;bic&quot;) ## [1] -2046.85 ネットワークのスコアが最大となるDAGを探索するためのアルゴリズム 山登り法 アークなしのDAGからスタートして1つひとつのアークを順次追加、除去、反転させることで最もネットワークスコアが増加する状況を探索する方法 hcを使ったらデフォルトはbicで計算される learned &lt;- hc(survey) modelstring(learned) ## [1] &quot;[R][E|R][T|R][A|E][O|E][S|E]&quot; score(learned, data = survey, type = &quot;bic&quot;) ## [1] -1998.432 arc.strength(learned, data = survey, criterion = &quot;bic&quot;) ## from to strength ## 1 R E -3.3896261 ## 2 E S -2.7260640 ## 3 R T -1.8484171 ## 4 E A -1.7195441 ## 5 E O -0.8266937 2.5 1.6離散型データでベイジアンネットワークを使ってみよう 2.5.1 1.6.1DAG構造を使って dsep(dag, x = &quot;S&quot;, y = &quot;R&quot;) ## [1] FALSE 教育水準(E)は性別(S)から影響を受けており、居住地(R)は教育水準(E)から影響を受けている（S→E、E→R）ので 性別(S)と居住地(R)が関連することは明らか 教育水準(E)を条件付けると性別(S)と居住地(R)の間のパスをブロックすることになるので独立になる dsep(dag, x = &quot;S&quot;, y = &quot;R&quot;, z = &quot;E&quot;) ## [1] TRUE \\[ Pr(O,R|E) = Pr(O|E)Pr(R|E) \\] 2.5.2 1.6.2条件付き確率表を使って 2.5.2.1 1.6.2.1厳密推論 library(gRain) ベイジアンネットワークを特別丹念に構築されたツリー構造に変換する方法に依拠している ツリー構造に対して、compile関数で確率表を計算できる→setEvicence関数を用いてエビデンスをjunctionオブジェクトに入力する 例）「女性が自動車や電車を利用することに対する態度」を調査したい。男女のサンプルvs女性だけのサンプルで比較したい #全体サンプル junction &lt;- compile(as.grain(bn)) querygrain(junction, nodes = &quot;T&quot;)$T ## T ## car train other ## 0.5618340 0.2808573 0.1573088 #女性だけのサンプル jsex &lt;- setEvidence(junction, nodes = &quot;S&quot;, states = &quot;F&quot;) querygrain(jsex, nodes = &quot;T&quot;)$T ## T ## car train other ## 0.5620577 0.2806144 0.1573280 →好みは同程度であった 例2）小規模の都市に居住することで利用する交通手段がどうかわるか jres &lt;- setEvidence(junction, nodes = &quot;R&quot;, states = &quot;small&quot;) querygrain(jres, nodes = &quot;T&quot;)$T ## T ## car train other ## 0.48388675 0.41708494 0.09902831 条件付き独立性を評価したい 例3）教育水準が与えられた場合の性別と交通手段の同時確率分布 jedu &lt;- setEvidence(junction, nodes = &quot;E&quot;, states = &quot;high&quot;) SxT.cpt &lt;- querygrain(jedu, nodes = c(&quot;S&quot;,&quot;T&quot;), type = &quot;conditional&quot;) SxT.cpt ## T ## S car train other ## M 0.612557 0.612557 0.612557 ## F 0.387443 0.387443 0.387443 2番目のノードで条件付けられた場合の1番目のノードの分布を算出できた 交通手段(T)がどのような状態でも男性にかかる条件付き確率は同じ→教育水準Eのもとで性別Sと交通手段Tは独立 2.5.2.2 1.6.2.2近似推論 ベイジアンネットワークを利用することで観測値をランダムに生成する方法（モンテカルロシミュレーション） 計算コストは高いが、多くのノードを含む大規模なBNを扱うことが可能 #あるエビデンスを与えた場合の特定のイベントに関する確率を算出する cpquery(bn, event = (S == &quot;M&quot;) &amp; (T == &quot;car&quot;), evidence = (E == &quot;high&quot;)) ## [1] 0.3428727 ただしquerygrain関数で出される正確な値とは多少異なる #nを増やせば多少改善はするが時間がかかる cpquery(bn, event = (S == &quot;M&quot;) &amp; (T == &quot;car&quot;), evidence = (E == &quot;high&quot;), n = 10^6) ## [1] 0.3418343 #尤度重み付き方法を使えば真値に非常に近い確率で算出可能 cpquery(bn, event = (S == &quot;M&quot;) &amp; (T == &quot;car&quot;), evidence = list(E = &quot;high&quot;), method = &quot;lw&quot;) ## [1] 0.3384312 #cpdist関数はエビデンスに適合するような変数のランダムな観測値を算出し、それを含んだdfを返す SxT &lt;- cpdist(bn, nodes = c(&quot;S&quot;, &quot;T&quot;), evidence = (E == &quot;high&quot;)) head(SxT) ## S T ## 1 F car ## 2 F other ## 3 M car ## 4 F other ## 5 M other ## 6 M train 2.6 1.7ベイジアンネットワークの図示 詳細は以下に記載あり https://www.bnlearn.com/examples/graphviz-plot/ graphviz.plot(dag) hlight &lt;- list(nodes = nodes(dag), arcs = arcs(dag), col = &quot;grey&quot;, textCol = &quot;grey&quot;) pp &lt;- graphviz.plot(dag, highlight = hlight, render = FALSE) library(Rgraphviz) edgeRenderInfo(pp) &lt;- list(col = c(&quot;S~E&quot; =&quot;black&quot;, &quot;E~R&quot; = &quot;black&quot;), lwd = c(&quot;S~E&quot; = 3, &quot;E~R&quot; = 3)) nodeRenderInfo(pp) &lt;- list(col = c(&quot;S&quot; = &quot;black&quot;, &quot;E&quot; = &quot;black&quot;, &quot;R&quot; = &quot;black&quot;), textCol = c(&quot;S&quot; = &quot;black&quot;, &quot;E&quot; = &quot;black&quot;, &quot;R&quot; = &quot;black&quot;), fill = c(&quot;E&quot; = &quot;grey&quot;)) renderGraph(pp) 2.6.1 1.7.2条件付き確率分布の図示 bn.fit.barchart(bn.mle$T, main = &quot;Travel&quot;, xlab = &quot;Pr(T|R,O)&quot;, ylab =&quot;&quot;) 交通手段の周辺確率と2つの条件付き確率クエリの結果を比較する Evidence &lt;- factor(c(rep(&quot;Unconditional&quot;,3), rep(&quot;Female&quot;, 3), rep(&quot;Small City&quot;,3)), levels = c(&quot;Unconditional&quot;, &quot;Female&quot;, &quot;Small City&quot;)) Travel &lt;- factor(rep(c(&quot;car&quot;, &quot;train&quot;, &quot;other&quot;), 3), levels = c(&quot;other&quot;, &quot;train&quot;, &quot;car&quot;)) distr &lt;- data.frame(Evidence = Evidence, Travel = Travel, Prob = c(0.5618, 0.2808, 0.15730, 0.5620, 0.2806, 0.1573, 0.4838, 0.4170, 0.0990)) distr ## Evidence Travel Prob ## 1 Unconditional car 0.5618 ## 2 Unconditional train 0.2808 ## 3 Unconditional other 0.1573 ## 4 Female car 0.5620 ## 5 Female train 0.2806 ## 6 Female other 0.1573 ## 7 Small City car 0.4838 ## 8 Small City train 0.4170 ## 9 Small City other 0.0990 library(lattice) barchart(Travel ~ Prob | Evidence, data = distr, layout = c(3, 1), xlab = &quot;probability&quot;, scales = list(alternating = 1, tck = c(1, 0)), strip = strip.custom(factor.levels = c(expression(Pr(T)), expression(Pr({T} * &quot; | &quot; * {S == F})), expression(Pr({T} * &quot; | &quot; * {R == small})))), panel = function(...) { panel.barchart(...) panel.grid(h = 0, v = -1) }) 仕様書 https://www.bnlearn.com/documentation/man/graphviz.chart.html このあたりはグラフ描画がうまくいかないのでパス。そこまで重要でもないし library(&quot;Rgraphviz&quot;) graphviz.chart(bn) graphviz.chart(as.bn.fit(jedu, including.evidence = TRUE), grid = TRUE, bar.col = c(A = &quot;black&quot;, S = &quot;black&quot;, E = &quot;grey&quot;, O = &quot;black&quot;, R = &quot;black&quot;, T = &quot;black&quot;), strip.bg = c(A = &quot;transparent&quot;, S = &quot;transparent&quot;, E = &quot;grey&quot;, O = &quot;transparent&quot;, R = &quot;transparent&quot;, T = &quot;transparent&quot;), main = &quot;BN with Evidence&quot;) "],["連続型データ事例ガウシアンベイジアンネットワーク.html", "3 2.連続型データ事例：ガウシアン・ベイジアンネットワーク 3.1 2.1事例紹介 3.2 2.2グラフィカル表現 3.3 2.3確率的表現 3.4 2.4パラメータの推定：相関係数 3.5 2.5DAG構造の学習：検定とスコア 3.6 2.6ガウシアン・ベイジアンネットワークを使ってみよう 3.7 2.7ガウシアン・ベイジアンネットワークの図示", " 3 2.連続型データ事例：ガウシアン・ベイジアンネットワーク 3.1 2.1事例紹介 遺伝的ポテンシャル：genetic potential;G 環境的ポテンシャル：environmental potential;E 種子の数;N 種子の平均重量;W 栄養器官：単一の植物に蓄えられる栄養に関する情報すべてを統合した変数;V 目的変数：作物の収穫量;C それぞれを1つの連続型変数として扱う 3.2 2.2グラフィカル表現 library(bnlearn) dag.bnlearn &lt;- model2network(&quot;[G][E][V|G:E][N|V][W|V][C|N:W]&quot;) dag.bnlearn ## ## Random/Generated Bayesian network ## ## model: ## [E][G][V|E:G][N|V][W|V][C|N:W] ## nodes: 6 ## arcs: 6 ## undirected arcs: 0 ## directed arcs: 6 ## average markov blanket size: 2.67 ## average neighbourhood size: 2.00 ## average branching factor: 1.00 ## ## generation algorithm: Empty graphviz.plot(dag.bnlearn) #どの変数の組み合わせが周辺的に独立しているか確認する crop.nodes &lt;- nodes(dag.bnlearn) for(n1 in crop.nodes){ for(n2 in crop.nodes){ if(dsep(dag.bnlearn, n1, n2)) cat(n1, &quot;and&quot;, n2, &quot;are independent.\\n&quot;) } } ## E and G are independent. ## G and E are independent. EとGのみが独立している、独立性は対称的だった #変数をすべての組あわせで対にして、栄養器官(V)で条件づけられた場合にどのペアが条件付き独立となるか確認できる for(n1 in crop.nodes[crop.nodes != &quot;V&quot;]){ for(n2 in crop.nodes[crop.nodes != &quot;V&quot;]){ if(n1&lt;n2){ if(dsep(dag.bnlearn, n1, n2, &quot;V&quot;)) cat(n1, &quot;and&quot;, n2, &quot;are independent given V.\\n&quot;) } } } ## C and E are independent given V. ## C and G are independent given V. ## E and N are independent given V. ## E and W are independent given V. ## G and N are independent given V. ## G and W are independent given V. ## N and W are independent given V. Vで条件づけられるとEとGは独立ではない 3.3 2.3確率的表現 #各パラメータの確率分布を定義する E.dist &lt;- list(coef = c(&quot;(Intercept)&quot; = 50), sd = 10) G.dist &lt;- list(coef = c(&quot;(Intercept)&quot; = 50), sd = 10) V.dist &lt;- list(coef = c(&quot;(Intercept)&quot; = -10.35534, E = 0.70711, G = 0.5), sd = 5) N.dist &lt;- list(coef = c(&quot;(Intercept)&quot; = 45, V = 0.1), sd = 9.949874) W.dist &lt;- list(coef = c(&quot;(Intercept)&quot; = 15, V = 0.7), sd = 7.141428) C.dist &lt;- list(coef = c(&quot;(Intercept)&quot; = 0, N = 0.3, W = 0.7), sd = 6.25) dist.list &lt;- list(E = E.dist, G = G.dist, V = V.dist, N = N.dist, W = W.dist, C = C.dist) gbn.bnlearn &lt;- custom.fit(dag.bnlearn, dist = dist.list) #局所分布のパラメータ gbn.bnlearn$C ## ## Parameters of node C (Gaussian distribution) ## ## Conditional density: C | N + W ## Coefficients: ## (Intercept) N W ## 0.0 0.3 0.7 ## Standard deviation of the residuals: 6.25 上記は線形ガウシアン・ベイジアンネットワークである すべてのノードは正規分布に基づく 親のノードをもたないノードは周辺分布により記述 各ノードの分散はそのノードに特有で親ノードに依存しない 各ノードの局所的分布は切片と親ノードを含んだ線形ガウシアンモデルとして表現 #ガウシアン・ベイジアンネットワークに特化したRパッケージ library(rbmn) #bn.fitオブジェクトを変換する gbn.rbmn &lt;- bnfit2nbn(gbn.bnlearn) #多変量正規分布のパラメータを得る gema.rbmn &lt;- nbn2gema(gbn.rbmn) mn.rbmn &lt;- gema2mn(gema.rbmn) print8mn(mn.rbmn) ## mu s.d. C.E C.G C.V C.W C.N C.C ## E 50 10 1.000 0.00 0.707 0.495 0.071 0.368 ## G 50 10 0.000 1.00 0.500 0.350 0.050 0.260 ## V 50 10 0.707 0.50 1.000 0.700 0.100 0.520 ## W 50 10 0.495 0.35 0.700 1.000 0.070 0.721 ## N 50 10 0.071 0.05 0.100 0.070 1.000 0.349 ## C 50 10 0.368 0.26 0.520 0.721 0.349 1.000 1列目：周辺分布の期待値 2列目：周辺分布の標準偏差 3列目以降：相関行列 3.4 2.4パラメータの推定：相関係数 DAG構造は既知とする #200の観測サンプルを生成して、cropdata200に格納する set.seed(4567) cropdata200 &lt;- rbn(gbn.bnlearn, n = 200) set.seed(1234) cropdata20k &lt;- rbn(gbn.bnlearn, n = 20000) dim(cropdata200) ## [1] 200 6 round(head(cropdata200), 2) ## C E G N V W ## 1 48.83 51.48 42.64 54.10 42.96 41.96 ## 2 48.85 73.43 40.97 60.07 65.29 48.96 ## 3 67.01 71.10 52.52 51.64 63.22 62.03 ## 4 37.83 49.33 56.15 49.01 47.75 38.77 ## 5 55.30 49.27 63.55 54.62 60.57 56.66 ## 6 56.12 48.72 66.02 43.95 55.54 52.39 #パラメータを推定する #変数が因子型でなければ自動的にガウシアン・ベイジアンネットワークと判断される crop.fitted &lt;- bn.fit(dag.bnlearn, data = cropdata200) crop.fitted ## ## Bayesian network parameters ## ## Parameters of node C (Gaussian distribution) ## ## Conditional density: C | N + W ## Coefficients: ## (Intercept) N W ## 2.4026177 0.2734476 0.6858202 ## Standard deviation of the residuals: 6.31327 ## ## Parameters of node E (Gaussian distribution) ## ## Conditional density: E ## Coefficients: ## (Intercept) ## 50.80161 ## Standard deviation of the residuals: 10.7432 ## ## Parameters of node G (Gaussian distribution) ## ## Conditional density: G ## Coefficients: ## (Intercept) ## 50.14396 ## Standard deviation of the residuals: 9.798923 ## ## Parameters of node N (Gaussian distribution) ## ## Conditional density: N | V ## Coefficients: ## (Intercept) V ## 51.81745022 -0.04461524 ## Standard deviation of the residuals: 9.531253 ## ## Parameters of node V (Gaussian distribution) ## ## Conditional density: V | E + G ## Coefficients: ## (Intercept) E G ## -10.4547647 0.7426946 0.4552872 ## Standard deviation of the residuals: 5.034309 ## ## Parameters of node W (Gaussian distribution) ## ## Conditional density: W | V ## Coefficients: ## (Intercept) V ## 20.1555287 0.5899971 ## Standard deviation of the residuals: 6.792171 #特定のノードについて異なるパラメータ推定法を用いることもできる crop.fitted$C &lt;- lm(C ~ N + W, data = cropdata200) crop.fitted$C ## ## Parameters of node C (Gaussian distribution) ## ## Conditional density: C | N + W ## Coefficients: ## (Intercept) N W ## 2.4026177 0.2734476 0.6858202 ## Standard deviation of the residuals: 6.31327 一般的な回帰モデルをもちいてパラメータ推定を行う リッジ、ラッソ回帰などについては以下を参照 https://aizine.ai/ridge-lasso-elasticnet/ #収穫量Cについてリッジ回帰を当てはめてみる library(penalized) crop.fitted$C &lt;- penalized(C ~ N + W, lambda1 = 0, lambda2 = 1.5, data = cropdata200) ## 1\b2\b 推定した値を真値（avg:50, sd:10)と比較する crop.fitted$E ## ## Parameters of node E (Gaussian distribution) ## ## Conditional density: E ## Coefficients: ## (Intercept) ## 50.80161 ## Standard deviation of the residuals: 10.7432 crop.fitted$C ## ## Parameters of node C (Gaussian distribution) ## ## Conditional density: C | N + W ## Coefficients: ## (Intercept) N W ## 2.4069159 0.2734233 0.6857580 ## Standard deviation of the residuals: 6.31327 NやW、SDについては真値に近似しているが、切片が0とは遠いので以下で直接修正する crop.fitted$C &lt;- lm(C ~ N + W - 1, data = cropdata200) crop.fitted$C ## ## Parameters of node C (Gaussian distribution) ## ## Conditional density: C | N + W ## Coefficients: ## (Intercept) N W ## 0.0000000 0.2963220 0.7105197 ## Standard deviation of the residuals: 6.304969 3.5 2.5DAG構造の学習：検定とスコア 3.5.1 2.5.1条件付き独立性検定 cormat &lt;- cor(cropdata200[, c(&quot;C&quot;, &quot;W&quot;, &quot;N&quot;)]) cormat ## C W N ## C 1.0000000 0.67479818 0.26480613 ## W 0.6747982 1.00000000 -0.02597999 ## N 0.2648061 -0.02597999 1.00000000 #cormat（相関行列）からinvcor(偏相関行列)を計算する #ほかのすべての変数で条件づけられた場合のXとYにおける偏相関という意味 library(corpcor) invcor &lt;- cor2pcor(cormat) dimnames(invcor) &lt;- dimnames(cormat) invcor ## C W N ## C 1.0000000 0.7071522 0.3826989 ## W 0.7071522 1.0000000 -0.2875974 ## N 0.3826989 -0.2875974 1.0000000 #種子の数Nで条件づけられた場合に作物の収穫量Cと種子の平均重量Wは独立か、という仮説を検証できる ci.test(&quot;C&quot;, &quot;W&quot;, &quot;N&quot;, test = &quot;cor&quot;, data = cropdata200) ## ## Pearson&#39;s Correlation ## ## data: C ~ W | N ## cor = 0.70715, df = 197, p-value &lt; 2.2e-16 ## alternative hypothesis: true value is not equal to 0 有意な偏相関があったことから帰無仮説を棄却し、独立でないと言える #200個のデータセットは大規模ではないので構造自体を学習させると以下のようになる pdag1 &lt;- iamb(cropdata200, test = &quot;cor&quot;) graphviz.plot(pdag1) #20kのデータセットを用いると正しく予測できる pdag2 &lt;- iamb(cropdata20k, test = &quot;cor&quot;) graphviz.plot(pdag2) #一部アークの追加、削除ができる wl &lt;- matrix(c(&quot;V&quot;, &quot;N&quot;), ncol = 2) pdag3 &lt;- iamb(cropdata200, test = &quot;cor&quot;, whitelist = wl) graphviz.plot(pdag3) 3.5.2 2.5.2ネットワークスコア \\[ BIC = \\log\\widehat{f}(E,G,V,N,W,C) - \\frac{d}{2}\\log n \\] また事後確率のスコアとしてBGe(Bayesian Gaussian equivalent score) score(dag.bnlearn, data = cropdata20k, type = &quot;bic-g&quot;) ## [1] -416421.2 score(dag.bnlearn, data = cropdata20k, type = &quot;bge&quot;) ## [1] -416494.5 3.6 2.6ガウシアン・ベイジアンネットワークを使ってみよう 3.6.1 2.6.1厳密推論 print8nbn(gbn.rbmn) ## =====Nodes===[parents] = Exp. (sd.dev) ## ----------------------------------------------- ## ---------E---[-] = 50 (10) ## ---------G---[-] = 50 (10) ## ---------V---[E,G] = -10.355 + 0.707*E + 0.5*G (5) ## ---------W---[V] = 15 + 0.7*V (7.141) ## ---------N---[V] = 45 + 0.1*V (9.95) ## ---------C---[N,W] = 0.3*N + 0.7*W (6.25) print8gema(gema.rbmn) ## mu E1 E2 E3 E4 E5 E6 ## E 50 10.000 0.0 0.0 0.000 0.000 0.00 ## G 50 0.000 10.0 0.0 0.000 0.000 0.00 ## V 50 7.071 5.0 5.0 0.000 0.000 0.00 ## W 50 4.950 3.5 3.5 7.141 0.000 0.00 ## N 50 0.707 0.5 0.5 0.000 9.950 0.00 ## C 50 3.677 2.6 2.6 4.999 2.985 6.25 別のノードの値を固定した場合の1つor複数のノードの条件付同時分布を算出可能 #Vを80に固定した場合のCの分布 print8mn(condi4joint(mn.rbmn, par = &quot;C&quot;, pour = &quot;V&quot;, x2 = 80)) ## mu s.d. ## C 65.6 8.542 3.6.2 2.6.2近似推論 3.6.3 シミュレーションを用いる 直接的：rnb関数 制約的：cpquery/cpdist関数 #(V,N)から観測値4つを生成する nobs &lt;- 4 sim &lt;- rbn(gbn.bnlearn, n = nobs) sim ## C E G N V W ## 1 65.41210 79.12004 67.14710 63.82861 79.28153 59.53187 ## 2 46.01587 35.57628 59.05068 51.74454 37.51262 40.01539 ## 3 63.36558 62.26097 48.24989 53.12280 57.59524 64.20510 ## 4 40.36104 35.87449 59.02320 37.77818 50.75239 47.35855 #条件を付けて生成する #非常に良質な作物を生産するための種子の数や平均重量はどのようなものか cpdist(gbn.bnlearn, nodes = c(&quot;C&quot;, &quot;N&quot;, &quot;W&quot;), evidence = (C &gt; 80)) ## C N W ## 1 82.73325 66.14010 73.51469 ## 2 81.32917 66.46854 80.87893 ## 3 83.71564 64.03459 75.02483 ## 4 81.56583 55.56495 63.87066 ## 5 81.67702 65.23859 65.27324 ## 6 80.12171 59.03308 72.62500 ## 7 84.46455 62.45442 68.80120 ## 8 82.76554 55.95147 71.92902 ## 9 85.34518 67.96205 77.49656 ## 10 81.56415 44.48874 76.90340 ## 11 82.04864 71.42499 81.17855 ## 12 80.33468 52.22056 74.36922 ## 13 82.70572 56.82981 59.85769 “=”を使って単一値を条件づける場合はこのアプローチは不可能となる 連続型分布において単一値はつねに確率がゼロであるから head(cpdist(gbn.bnlearn, nodes = c(&quot;V&quot;,&quot;G&quot;,&quot;E&quot;), evidence = list(G = 10, E = 90), method = &quot;lw&quot;), n = 5) ## V G E ## 1 63.71504 10 90 ## 2 62.78473 10 90 ## 3 67.95987 10 90 ## 4 53.36817 10 90 ## 5 58.42986 10 90 尤度重み付け法を用いることで解決することができる #特定のイベントに関する確率を算出できる cpquery(gbn.bnlearn, event = (V &gt; 70), evidence = list(G = 10, E = 90), method = &quot;lw&quot;) ## [1] 0.009666667 3.7 2.7ガウシアン・ベイジアンネットワークの図示 3.7.1 2.7.1DAGの図示 library(igraph) igraph.options(print.full = TRUE) dag0.igraph &lt;- graph.formula(G-+V, E-+V, V-+N, V-+W, N-+C, W-+C) dag0.igraph ## IGRAPH 0f56d87 DN-- 6 6 -- ## + attr: name (v/c) ## + edges from 0f56d87 (vertex names): ## [1] G-&gt;V V-&gt;N V-&gt;W E-&gt;V N-&gt;C W-&gt;C #bnから変換もできる dag.igraph &lt;- as.igraph(dag.bnlearn) #ノードを表す V(dag.igraph) ## + 6/6 vertices, named, from 0f5c0b2: ## [1] C E G N V W #エッジを表す E(dag.igraph) ## + 6/6 edges from 0f5c0b2 (vertex names): ## [1] G-&gt;V E-&gt;V V-&gt;N V-&gt;W N-&gt;C W-&gt;C par(mfrow = c(1, 3), mar = rep(3, 4), cex.main = 2) plot(dag.igraph, main = &quot;\\n1: defaults&quot;) ly &lt;- matrix(c(2, 3, 1, 1, 2, 3, 1, 4, 4, 2, 3, 2), 6) plot(dag.igraph, layout = ly, main = &quot;\\n2: positioning&quot;) vcol &lt;- c(&quot;black&quot;, &quot;darkgrey&quot;, &quot;darkgrey&quot;, rep(NA, 3)) lcol &lt;- c(rep(&quot;white&quot;, 3), rep(NA, 3)) par(mar = rep(0, 4), lwd = 1.5) plot(dag.igraph, layout = ly, frame = TRUE, main = &quot;\\n3: final&quot;, vertex.color = vcol, vertex.label.color = lcol, vertex.label.cex = 3, vertex.size = 50, edge.arrow.size = 0.8, edge.color = &quot;black&quot;) 3.7.2 2.7.2条件付き確率分布の図示 ガウシアン・ベイジアンネットワークの局所的分布を図示するための関数はない 線形回帰モデルのための回帰診断図を利用することは可能 ただし、残差と当てはめ値がbn.fitオブジェクトに格納されている必要がある gbn.fit &lt;- bn.fit(dag.bnlearn, data = cropdata20k) #残差に関するquantile-quantileプロット bn.fit.qqplot(gbn.fit) #理論上の正規密度分布と重ねた残差のヒストグラム bn.fit.histogram(gbn.fit) #当てはめ値に対する残差プロット bn.fit.xyplot(gbn.fit) #一つのノードのみに着目した図もかける bn.fit.qqplot(gbn.fit$C) 環境的ポテンシャルEと栄養期間Vの組み合わせに対してどのように収穫量Cが変化するのかについて興味があるとする（C|E,V) C.EV &lt;- condi4joint(mn.rbmn, par = &quot;C&quot;, pour = c(&quot;E&quot;, &quot;V&quot;), x2 = NULL) C.EV$rho ## E V ## C 0 0.52 Vに関する情報が得られたときはEに関する回帰係数が0になる→Cを推定するに当たりEに関する情報は役に立たない #VがEとCと有効分離の関係にある dsep(gbn.bnlearn, &quot;E&quot;,&quot;C&quot;,&quot;V&quot;) ## [1] TRUE EとVの両方を変化させた場合のCに関する分布を算出したい 3次元プロットは難しくエラーが発生しやすいので、二次元で観測値のポイントの大きさを変えることで表現する set.seed(5678) cropdata3 &lt;- cpdist(gbn.bnlearn, nodes = c(&quot;E&quot;, &quot;V&quot;, &quot;C&quot;), evidence = TRUE, n = 1000) plot(cropdata3$V, cropdata3$C, type = &quot;n&quot;, main = &quot;C|V,E; E is the point size&quot;) cexlim &lt;- c(0.1, 2.4) cexE &lt;- cexlim[1] + diff(cexlim) / diff(range(cropdata3$E) * (cropdata3$E - min(cropdata3$E))) points(cropdata3$V, cropdata3$C, cex = cexE*10) cqa &lt;- quantile(cropdata3$C, seq(0, 1, 0.1)) abline(h = cqa, lty = 3) "],["混合事例条件付きガウシアンベイジアンネットワーク.html", "4 3.混合事例：条件付きガウシアン・ベイジアンネットワーク 4.1 3.1事例紹介：健康管理にかかるコスト 4.2 3.3パラメータの推定：混合回帰", " 4 3.混合事例：条件付きガウシアン・ベイジアンネットワーク 4.1 3.1事例紹介：健康管理にかかるコスト Age:A; 離散型 Pre-existing conditions:C; 離散型：既往歴 Outpatient expenditure:O; 連続型：通院にかかる費用 Inpatient expenditure:I;連続型：入院にかかる支出 Any hospital stay:H;離散型：入院該当の有無 Days of hospital stay:D; 連続型：入院日数 Taxes:T;連続型：医療費にかかる税金 dag &lt;- model2network(&quot;[A][C|A][H|A][D|A:H][I|C:D][O|A][T|O:I]&quot;) graphviz.plot(dag) #Aの条件付き確率表作成 A.lv &lt;- c(&quot;young&quot;, &quot;adult&quot;, &quot;old&quot;) A.prob &lt;- array(c(0.35, 0.45, 0.20), dim = 3, dimnames = list(A = A.lv)) A.prob ## A ## young adult old ## 0.35 0.45 0.20 年齢に応じて既往症のレベルが異なるようにCを条件付ける C.lv &lt;- c(&quot;none&quot;, &quot;mild&quot;, &quot;severe&quot;) C.prob &lt;- array(c(0.88, 0.10, 0.02, 0.75, 0.20, 0.05, 0.42, 0.53, 0.05), dim = c(3, 3), dimnames = list(C = C.lv, A = A.lv)) C.prob ## A ## C young adult old ## none 0.88 0.75 0.42 ## mild 0.10 0.20 0.53 ## severe 0.02 0.05 0.05 H.lv &lt;- c(&quot;none&quot;, &quot;any&quot;) H.prob &lt;- array(c(0.90, 0.10, 0.75, 0.25, 0.60, 0.40), dim = c(2, 3), dimnames = list(H = H.lv, A = A.lv)) H.prob ## A ## H young adult old ## none 0.9 0.75 0.6 ## any 0.1 0.25 0.4 D.coef &lt;- list(coef = array(c(0, 0, 0, 1, 4, 7), dim = c(1, 6), dimnames = list(&quot;(Intercept)&quot;, NULL)), sd = c(0, 0, 0, 0.5, 1, 1.5)) D.coef ## $coef ## [,1] [,2] [,3] [,4] [,5] [,6] ## (Intercept) 0 0 0 1 4 7 ## ## $sd ## [1] 0.0 0.0 0.0 0.5 1.0 1.5 DはH(入院の有無)×A(young mild old)に対応している Hがnoneなら0 離散型変数→連続型変数の場合 親ノードの離散型変数の値に応じて複数の線形回帰モデルをセットとして表現する 連続型変数が複数の離散型変数を親ノードとして持つ場合 親ノードの値に対応した回帰モデルを複数含む形で構成される 連続型変数の親ノードが連続型変数である場合 親ノードの連続型変数が子ノードの下位モデルに混在する形 I.coef &lt;- list(coef = array(c(1, 3, 1, 5.5, 1, 8) * 100 , dim = c(2, 3), dimnames = list(c(&quot;(Intercept)&quot;, &quot;D&quot;), NULL)) , sd = c(30, 50, 100)) I.coef ## $coef ## [,1] [,2] [,3] ## (Intercept) 100 100 100 ## D 300 550 800 ## ## $sd ## [1] 30 50 100 O.coef &lt;- list(coef = array(c(60, 180, 360), dim = c(1, 3), dimnames = list(&quot;(Intercept)&quot;, NULL)), sd = c(10, 20, 40)) T.coef &lt;- list(coef = c(&quot;(Intercept)&quot; = 120, I = 1.02, O = 1.05), sd = 10) \\[ T= 120+1.02I+1.05O+\\varepsilon_T\\sim N(0,10^2) \\] 上記内容でBNを定義したのでbn.fitオブジェクトを作成する dists &lt;- list(A = A.prob, C= C.prob, H = H.prob, D= D.coef, I = I.coef, O = O.coef, &quot;T&quot; = T.coef) healthcare &lt;- custom.fit(dag, dists) healthcare$I ## ## Parameters of node I (conditional Gaussian distribution) ## ## Conditional density: I | C + D ## Coefficients: ## 0 1 2 ## (Intercept) 100 100 100 ## D 300 550 800 ## Standard deviation of the residuals: ## 0 1 2 ## 30 50 100 ## Discrete parents&#39; configurations: ## C ## 0 none ## 1 mild ## 2 severe 上記で構築したものが、条件付きガウシアン・ベイジアンネットワーク（CGBN）である。 離散型ノードは多項分布に従う 連続型ノード（親ノードに離散型を含まない）は正規分布に従う 1つ以上の離散型ノードの親を持つ連続型ノードは、離散型変数である親の状態を組み合わせた中における1つの要素の混合正規分布に従う 混合状態における各要素は独立したパラメータを持つ 連続型ノードは連続型ノード、離散型ノードいずれも親にできる 離散型ノードは離散型ノードしか親にできない 4.2 3.3パラメータの推定：混合回帰 すでにDAGは既知であるとする costs &lt;- read.table(&quot;data/healthcare.txt&quot;, header = TRUE, colClasses = c(&quot;factor&quot;, &quot;factor&quot;, &quot;numeric&quot;, &quot;factor&quot;, &quot;numeric&quot;, &quot;numeric&quot;, &quot;numeric&quot;)) #最尤推定法で局所的分布のパラメータを推定した fitted &lt;- bn.fit(dag, data = costs) #今回推定したもの coef(fitted$H) ## A ## H adult old young ## any 0.2380435 0.4239401 0.1060383 ## none 0.7619565 0.5760599 0.8939617 #経験的頻度を用いて推定したもの→つまり実際の値から算出される確率 cpt.H &lt;- prop.table(table(costs[, c(&quot;H&quot;, &quot;A&quot;)]), margin = 2) #これをfitの推定値と比較してみる all.equal(cpt.H, coef(fitted$H)) ## [1] TRUE 同じものが得られている "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
